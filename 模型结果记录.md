| 模型                 | 训练准确率   | 预测准确率   | 备注                         | 模型.1        | 训练准确率.1   |   预测准确率.1 | 备注.1      |
|:-------------------|:--------|:--------|:---------------------------|:------------|:----------|----------:|:----------|
| Attention_LSTM     | 0.93    | 0.86    | 速度较快                       | BoW+RF      | /         |      0.85 | 速度较快，效果还行 |
| BERT_Native        | 0.96    | 0.91    | 速度非常慢，显存占用较高               | Word2Vec+RF | /         |      0.83 | 速度较快，效果还行 |
| BERT_Scratch       | /       | /       | 适配了最新的库，跑不出来               | nan         | nan       |    nan    | nan       |
| BERT_Trainer       | /       | /       | 适配了最新的库，跑不出来               | nan         | nan       |    nan    | nan       |
| Capsule_LSTM       | /       | /       | input和target的batch_size不匹配 | nan         | nan       |    nan    | nan       |
| CNN                | 0.75    | 0.75    | 改为跑20轮，效果有一定提升             | nan         | nan       |    nan    | nan       |
| CNN_LSTM           | 0.81    | 0.78    | 比起纯CNN效果有一定提升              | nan         | nan       |    nan    | nan       |
| DistilBERT_Native  | 0.97    | 0.91    | 速度非常慢，显存占用非常高              | nan         | nan       |    nan    | nan       |
| DistilBERT_Trainer | 0.93    | 0.93    | 适配了最新的库，kaggle跑出来了         | nan         | nan       |    nan    | nan       |
| GRU                | 0.86    | 0.86    | 速度较快，效果还行                  | nan         | nan       |    nan    | nan       |
| LSTM               | 0.75    | 0.75    | 速度较快，效果一般                  | nan         | nan       |    nan    | nan       |
| RoBERTa_Trainer    | /       | /       | nan                        | nan         | nan       |    nan    | nan       |
| Transformer        | /       | /       | size of tensor不匹配          | nan         | nan       |    nan    | nan       |